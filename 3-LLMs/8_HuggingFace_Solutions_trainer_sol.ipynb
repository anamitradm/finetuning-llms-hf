{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88857f1d",
   "metadata": {},
   "source": [
    "# TensorFlow Solutions for HuggingFace Exercises\n",
    "\n",
    "This notebook provides TensorFlow solutions for three of the exercises from the HuggingFace exercises notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37c92e",
   "metadata": {},
   "source": [
    "## Exercise 1: Downloading and Prompting T5 with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f80245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4964b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_with_t5(text, model, tokenizer, source_lang=\"English\", target_lang=\"French\"):\n",
    "    input_text = f\"Translate {source_lang} to {target_lang}: {text}\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"tf\")\n",
    "    outputs = model.generate(inputs)\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "translate_with_t5(\"Hello, world!\", model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8c676",
   "metadata": {},
   "source": [
    "## Exercise 2: Transfer Learning with BERT in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tensorflow-datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer, glue_convert_examples_to_features\n",
    "\n",
    "# Loading the IMDB reviews dataset\n",
    "data = tfds.load('imdb_reviews', split=['train', 'test'], as_supervised=True)\n",
    "train_data, test_data = data[0], data[1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_examples(ds, limit=-1, batch_size=32):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "\n",
    "    for review, label in tfds.as_numpy(ds.take(limit)):\n",
    "        bert_input = tokenizer.encode_plus(\n",
    "            review.decode('utf-8'),\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "\n",
    "        input_ids.append(bert_input['input_ids'][0])\n",
    "        attention_masks.append(bert_input['attention_mask'][0])\n",
    "        labels.append(label)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(({\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "    }, labels)).shuffle(len(labels)).batch(batch_size)\n",
    "\n",
    "# Apply the function to the train and test dataset\n",
    "batch_size = 32\n",
    "train_data_encoded = encode_examples(train_data, batch_size=batch_size, limit=10000)\n",
    "test_data_encoded = encode_examples(test_data, batch_size=batch_size, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n",
    "\n",
    "# Model training\n",
    "epochs = 3  # Adjust as needed\n",
    "model.fit(train_data_encoded, epochs=epochs, validation_data=test_data_encoded)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "5b0eb659",
   "metadata": {},
   "source": [
    "## Exercise 3: Distillation of BERT using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91a064",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Understanding model distillation\n",
    "# Distillation involves training a smaller model (student) to mimic a larger model (teacher).\n",
    "# Here we assume the use of a smaller BERT model as the student.\n",
    "# The distillation process involves training the student model to replicate the teacher model's output.\n",
    "# Detailed code for this process is complex and is not provided in this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4: Using ROUGE for Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "!pip install tensorflow transformers rouge-score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Loading the model and tokenizer for summarization\n",
    "model_name = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Function to perform summarization\n",
    "def summarize(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"tf\", max_length=512)\n",
    "    outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example text\n",
    "example_text = \"The quick brown fox jumps over the lazy dog. This is an example sentence to demonstrate text summarization.\"\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarize(example_text)\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(example_text, summary)\n",
    "\n",
    "summary, scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 5: Exploring BLEU for Machine Translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "!pip install tensorflow transformers sacrebleu\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import sacrebleu\n",
    "\n",
    "# Loading the model and tokenizer for translation\n",
    "model_name = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Function to perform translation\n",
    "def translate(text, target_language=\"fr\"):\n",
    "    inputs = tokenizer.encode(\"translate English to \" + target_language + \": \" + text, return_tensors=\"tf\", max_length=512)\n",
    "    outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example text\n",
    "example_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Translate the text\n",
    "translation = translate(example_text, \"fr\")\n",
    "\n",
    "# Evaluate using BLEU\n",
    "reference = [\"Le rapide renard brun saute par-dessus le chien paresseux.\"]\n",
    "bleu_score = sacrebleu.corpus_bleu([translation], [reference])\n",
    "\n",
    "translation, bleu_score.score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}